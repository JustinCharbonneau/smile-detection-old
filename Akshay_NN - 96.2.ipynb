{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(2)\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Plot architecture\n",
    "import keras\n",
    "import pydot\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[182. 182. 182.]\n",
      "   [177. 177. 177.]\n",
      "   [105. 105. 105.]\n",
      "   ...\n",
      "   [ 49.  49.  49.]\n",
      "   [ 56.  56.  56.]\n",
      "   [ 63.  63.  63.]]\n",
      "\n",
      "  [[ 92.  92.  92.]\n",
      "   [ 71.  71.  71.]\n",
      "   [ 65.  65.  65.]\n",
      "   ...\n",
      "   [ 27.  27.  27.]\n",
      "   [ 36.  36.  36.]\n",
      "   [ 39.  39.  39.]]\n",
      "\n",
      "  [[ 30.  30.  30.]\n",
      "   [ 30.  30.  30.]\n",
      "   [ 22.  22.  22.]\n",
      "   ...\n",
      "   [ 15.  15.  15.]\n",
      "   [ 20.  20.  20.]\n",
      "   [ 23.  23.  23.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[154. 154. 154.]\n",
      "   [187. 187. 187.]\n",
      "   [202. 202. 202.]\n",
      "   ...\n",
      "   [ 88.  88.  88.]\n",
      "   [ 88.  88.  88.]\n",
      "   [ 88.  88.  88.]]\n",
      "\n",
      "  [[119. 119. 119.]\n",
      "   [167. 167. 167.]\n",
      "   [158. 158. 158.]\n",
      "   ...\n",
      "   [ 88.  88.  88.]\n",
      "   [ 67.  67.  67.]\n",
      "   [ 67.  67.  67.]]\n",
      "\n",
      "  [[109. 109. 109.]\n",
      "   [116. 116. 116.]\n",
      "   [158. 158. 158.]\n",
      "   ...\n",
      "   [ 78.  78.  78.]\n",
      "   [101. 101. 101.]\n",
      "   [119. 119. 119.]]]\n",
      "\n",
      "\n",
      " [[[109. 109. 109.]\n",
      "   [ 82.  82.  82.]\n",
      "   [ 68.  68.  68.]\n",
      "   ...\n",
      "   [ 36.  36.  36.]\n",
      "   [ 64.  64.  64.]\n",
      "   [117. 117. 117.]]\n",
      "\n",
      "  [[ 39.  39.  39.]\n",
      "   [ 40.  40.  40.]\n",
      "   [ 36.  36.  36.]\n",
      "   ...\n",
      "   [ 15.  15.  15.]\n",
      "   [ 20.  20.  20.]\n",
      "   [ 33.  33.  33.]]\n",
      "\n",
      "  [[ 42.  42.  42.]\n",
      "   [ 35.  35.  35.]\n",
      "   [ 30.  30.  30.]\n",
      "   ...\n",
      "   [ 14.  14.  14.]\n",
      "   [ 13.  13.  13.]\n",
      "   [ 20.  20.  20.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[106. 106. 106.]\n",
      "   [103. 103. 103.]\n",
      "   [ 90.  90.  90.]\n",
      "   ...\n",
      "   [ 55.  55.  55.]\n",
      "   [ 56.  56.  56.]\n",
      "   [ 48.  48.  48.]]\n",
      "\n",
      "  [[125. 125. 125.]\n",
      "   [109. 109. 109.]\n",
      "   [ 77.  77.  77.]\n",
      "   ...\n",
      "   [ 52.  52.  52.]\n",
      "   [ 40.  40.  40.]\n",
      "   [ 37.  37.  37.]]\n",
      "\n",
      "  [[154. 154. 154.]\n",
      "   [122. 122. 122.]\n",
      "   [ 77.  77.  77.]\n",
      "   ...\n",
      "   [ 47.  47.  47.]\n",
      "   [ 40.  40.  40.]\n",
      "   [ 57.  57.  57.]]]\n",
      "\n",
      "\n",
      " [[[ 87.  87.  87.]\n",
      "   [ 93.  93.  93.]\n",
      "   [ 88.  88.  88.]\n",
      "   ...\n",
      "   [ 17.  17.  17.]\n",
      "   [ 17.  17.  17.]\n",
      "   [ 18.  18.  18.]]\n",
      "\n",
      "  [[ 93.  93.  93.]\n",
      "   [107. 107. 107.]\n",
      "   [131. 131. 131.]\n",
      "   ...\n",
      "   [ 22.  22.  22.]\n",
      "   [ 24.  24.  24.]\n",
      "   [ 27.  27.  27.]]\n",
      "\n",
      "  [[141. 141. 141.]\n",
      "   [125. 125. 125.]\n",
      "   [125. 125. 125.]\n",
      "   ...\n",
      "   [ 72.  72.  72.]\n",
      "   [ 50.  50.  50.]\n",
      "   [ 42.  42.  42.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   [ 59.  59.  59.]\n",
      "   ...\n",
      "   [201. 201. 201.]\n",
      "   [212. 212. 212.]\n",
      "   [204. 204. 204.]]\n",
      "\n",
      "  [[255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   [227. 227. 227.]\n",
      "   ...\n",
      "   [221. 221. 221.]\n",
      "   [221. 221. 221.]\n",
      "   [226. 226. 226.]]\n",
      "\n",
      "  [[255. 255. 255.]\n",
      "   [255. 255. 255.]\n",
      "   [254. 254. 254.]\n",
      "   ...\n",
      "   [243. 243. 243.]\n",
      "   [235. 235. 235.]\n",
      "   [235. 235. 235.]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[ 51.  51.  51.]\n",
      "   [ 48.  48.  48.]\n",
      "   [ 49.  49.  49.]\n",
      "   ...\n",
      "   [ 35.  35.  35.]\n",
      "   [ 47.  47.  47.]\n",
      "   [ 19.  19.  19.]]\n",
      "\n",
      "  [[ 41.  41.  41.]\n",
      "   [ 53.  53.  53.]\n",
      "   [ 62.  62.  62.]\n",
      "   ...\n",
      "   [ 25.  25.  25.]\n",
      "   [ 32.  32.  32.]\n",
      "   [ 41.  41.  41.]]\n",
      "\n",
      "  [[ 62.  62.  62.]\n",
      "   [ 43.  43.  43.]\n",
      "   [ 25.  25.  25.]\n",
      "   ...\n",
      "   [ 35.  35.  35.]\n",
      "   [ 35.  35.  35.]\n",
      "   [ 37.  37.  37.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[162. 162. 162.]\n",
      "   [146. 146. 146.]\n",
      "   [132. 132. 132.]\n",
      "   ...\n",
      "   [ 95.  95.  95.]\n",
      "   [132. 132. 132.]\n",
      "   [200. 200. 200.]]\n",
      "\n",
      "  [[169. 169. 169.]\n",
      "   [146. 146. 146.]\n",
      "   [135. 135. 135.]\n",
      "   ...\n",
      "   [ 95.  95.  95.]\n",
      "   [137. 137. 137.]\n",
      "   [203. 203. 203.]]\n",
      "\n",
      "  [[166. 166. 166.]\n",
      "   [162. 162. 162.]\n",
      "   [138. 138. 138.]\n",
      "   ...\n",
      "   [ 95.  95.  95.]\n",
      "   [154. 154. 154.]\n",
      "   [203. 203. 203.]]]\n",
      "\n",
      "\n",
      " [[[192. 192. 192.]\n",
      "   [123. 123. 123.]\n",
      "   [ 68.  68.  68.]\n",
      "   ...\n",
      "   [ 30.  30.  30.]\n",
      "   [ 58.  58.  58.]\n",
      "   [109. 109. 109.]]\n",
      "\n",
      "  [[ 62.  62.  62.]\n",
      "   [ 58.  58.  58.]\n",
      "   [ 48.  48.  48.]\n",
      "   ...\n",
      "   [ 23.  23.  23.]\n",
      "   [ 19.  19.  19.]\n",
      "   [ 23.  23.  23.]]\n",
      "\n",
      "  [[ 53.  53.  53.]\n",
      "   [ 53.  53.  53.]\n",
      "   [ 47.  47.  47.]\n",
      "   ...\n",
      "   [ 23.  23.  23.]\n",
      "   [ 27.  27.  27.]\n",
      "   [ 23.  23.  23.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[138. 138. 138.]\n",
      "   [128. 128. 128.]\n",
      "   [128. 128. 128.]\n",
      "   ...\n",
      "   [ 48.  48.  48.]\n",
      "   [ 58.  58.  58.]\n",
      "   [ 63.  63.  63.]]\n",
      "\n",
      "  [[128. 128. 128.]\n",
      "   [123. 123. 123.]\n",
      "   [122. 122. 122.]\n",
      "   ...\n",
      "   [ 53.  53.  53.]\n",
      "   [ 57.  57.  57.]\n",
      "   [ 63.  63.  63.]]\n",
      "\n",
      "  [[128. 128. 128.]\n",
      "   [119. 119. 119.]\n",
      "   [114. 114. 114.]\n",
      "   ...\n",
      "   [ 45.  45.  45.]\n",
      "   [ 63.  63.  63.]\n",
      "   [ 68.  68.  68.]]]\n",
      "\n",
      "\n",
      " [[[ 79.  79.  79.]\n",
      "   [123. 123. 123.]\n",
      "   [148. 148. 148.]\n",
      "   ...\n",
      "   [ 33.  33.  33.]\n",
      "   [ 41.  41.  41.]\n",
      "   [ 75.  75.  75.]]\n",
      "\n",
      "  [[ 49.  49.  49.]\n",
      "   [ 50.  50.  50.]\n",
      "   [ 59.  59.  59.]\n",
      "   ...\n",
      "   [ 80.  80.  80.]\n",
      "   [ 68.  68.  68.]\n",
      "   [ 47.  47.  47.]]\n",
      "\n",
      "  [[ 35.  35.  35.]\n",
      "   [ 49.  49.  49.]\n",
      "   [ 75.  75.  75.]\n",
      "   ...\n",
      "   [129. 129. 129.]\n",
      "   [126. 126. 126.]\n",
      "   [106. 106. 106.]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[168. 168. 168.]\n",
      "   [163. 163. 163.]\n",
      "   [153. 153. 153.]\n",
      "   ...\n",
      "   [119. 119. 119.]\n",
      "   [123. 123. 123.]\n",
      "   [123. 123. 123.]]\n",
      "\n",
      "  [[135. 135. 135.]\n",
      "   [158. 158. 158.]\n",
      "   [158. 158. 158.]\n",
      "   ...\n",
      "   [123. 123. 123.]\n",
      "   [ 59.  59.  59.]\n",
      "   [ 16.  16.  16.]]\n",
      "\n",
      "  [[ 76.  76.  76.]\n",
      "   [ 75.  75.  75.]\n",
      "   [148. 148. 148.]\n",
      "   ...\n",
      "   [ 51.  51.  51.]\n",
      "   [  6.   6.   6.]\n",
      "   [ 11.  11.  11.]]]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>95a.JPG</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>33a.JPG</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>225</td>\n",
       "      <td>26b.JPG</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>157</td>\n",
       "      <td>158a.JPG</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>356</td>\n",
       "      <td>157b.JPG</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>395</td>\n",
       "      <td>299</td>\n",
       "      <td>100b.JPG</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>396</td>\n",
       "      <td>22</td>\n",
       "      <td>23a.JPG</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>397</td>\n",
       "      <td>72</td>\n",
       "      <td>73a.JPG</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>398</td>\n",
       "      <td>15</td>\n",
       "      <td>16a.JPG</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>399</td>\n",
       "      <td>168</td>\n",
       "      <td>169a.JPG</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index     fname    label\n",
       "0       94   95a.JPG  neutral\n",
       "1       32   33a.JPG  neutral\n",
       "2      225   26b.JPG    happy\n",
       "3      157  158a.JPG  neutral\n",
       "4      356  157b.JPG    happy\n",
       "..     ...       ...      ...\n",
       "395    299  100b.JPG    happy\n",
       "396     22   23a.JPG  neutral\n",
       "397     72   73a.JPG  neutral\n",
       "398     15   16a.JPG  neutral\n",
       "399    168  169a.JPG  neutral\n",
       "\n",
       "[400 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the annotations file that contains the label and the image file name\n",
    "labels = pd.read_csv('./SMILE_Dataset/annotations.csv', header=None, names=['fname','label'])\n",
    "\n",
    "# Shuffle data\n",
    "labels = labels.sample(frac=1).reset_index()\n",
    "\n",
    "# Use a list comprehension to loop over image file names and import one by one and store pixel values\n",
    "x = np.array([image.img_to_array(image.load_img('./SMILE_Dataset/all/'+fname, target_size=(64, 64))) for fname in labels['fname']])\n",
    "print(x)\n",
    "# Because the names are strings, the neural network only takes in numerical formats so we will one-hot encode the label\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(labels['label'])\n",
    "y = integer_encoded\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pizza_model():\n",
    "    \n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=(64, 64, 3)))\n",
    "    model.add(layers.Dense(80, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizers.Adam(lr=0.001),\n",
    "                  metrics=['acc'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kfold iteration 1/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 1.0042 - acc: 0.5500 - val_loss: 197.5574 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.7143 - acc: 0.6028 - val_loss: 1.4423 - val_acc: 0.9250\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4956 - acc: 0.7806 - val_loss: 5.0159 - val_acc: 0.9750\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.3998 - acc: 0.8306 - val_loss: 9.3075 - val_acc: 0.9750\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.3408 - acc: 0.8361 - val_loss: 2.2064 - val_acc: 0.9750\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3269 - acc: 0.8750 - val_loss: 5.9478 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.2435 - acc: 0.8944 - val_loss: 8.4024 - val_acc: 0.9750\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2066 - acc: 0.9194 - val_loss: 1.7779 - val_acc: 0.9750\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1902 - acc: 0.9278 - val_loss: 4.3058 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2024 - acc: 0.9222 - val_loss: 1.3632 - val_acc: 0.9750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        20\n",
      "           1       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.98      0.97      0.97        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "Kfold iteration 2/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1.0238 - acc: 0.5639 - val_loss: 53.6874 - val_acc: 0.5750\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.5089 - acc: 0.7472 - val_loss: 15.7452 - val_acc: 0.8750\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4120 - acc: 0.8250 - val_loss: 114.4637 - val_acc: 0.6750\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3234 - acc: 0.8528 - val_loss: 6.9488 - val_acc: 0.9750\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4049 - acc: 0.8167 - val_loss: 2.5540 - val_acc: 0.9750\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2984 - acc: 0.8806 - val_loss: 12.2355 - val_acc: 0.9750\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2188 - acc: 0.9111 - val_loss: 16.6321 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2609 - acc: 0.9111 - val_loss: 8.5316 - val_acc: 0.9750\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2168 - acc: 0.9167 - val_loss: 16.5409 - val_acc: 0.9750\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2029 - acc: 0.9306 - val_loss: 4.2424 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        20\n",
      "           1       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.98      0.97      0.97        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "Kfold iteration 3/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.8397 - acc: 0.5722 - val_loss: 22.6274 - val_acc: 0.8000\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4458 - acc: 0.8194 - val_loss: 49.0258 - val_acc: 0.8500\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2963 - acc: 0.8806 - val_loss: 70.7084 - val_acc: 0.8500\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.3244 - acc: 0.8889 - val_loss: 134.5467 - val_acc: 0.7000\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.3367 - acc: 0.8667 - val_loss: 57.8938 - val_acc: 0.8750\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2777 - acc: 0.8861 - val_loss: 59.7946 - val_acc: 0.9000\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2457 - acc: 0.9167 - val_loss: 72.8155 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2450 - acc: 0.9028 - val_loss: 67.3649 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.2694 - acc: 0.9000 - val_loss: 60.1668 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1697 - acc: 0.9306 - val_loss: 65.2806 - val_acc: 0.9000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.90      0.90        20\n",
      "           1       0.90      0.90      0.90        20\n",
      "\n",
      "    accuracy                           0.90        40\n",
      "   macro avg       0.90      0.90      0.90        40\n",
      "weighted avg       0.90      0.90      0.90        40\n",
      "\n",
      "Kfold iteration 4/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.8530 - acc: 0.5361 - val_loss: 0.6907 - val_acc: 0.9250\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.6956 - acc: 0.6111 - val_loss: 2.6808 - val_acc: 0.9500\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.5035 - acc: 0.7667 - val_loss: 0.4467 - val_acc: 0.9750\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3017 - acc: 0.8972 - val_loss: 3.5125 - val_acc: 0.9750\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3191 - acc: 0.8611 - val_loss: 3.1813 - val_acc: 0.9750\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.2220 - acc: 0.9111 - val_loss: 13.4383 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2283 - acc: 0.9028 - val_loss: 12.4254 - val_acc: 0.9750\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2202 - acc: 0.9250 - val_loss: 19.0689 - val_acc: 0.9750\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2299 - acc: 0.9083 - val_loss: 14.4345 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2225 - acc: 0.9194 - val_loss: 12.7226 - val_acc: 0.9750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        20\n",
      "           1       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.98      0.97      0.97        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "Kfold iteration 5/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.8989 - acc: 0.5361 - val_loss: 0.2023 - val_acc: 0.9750\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.4926 - acc: 0.7833 - val_loss: 3.7734e-24 - val_acc: 1.0000\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.3330 - acc: 0.8750 - val_loss: 7.3394 - val_acc: 0.9750\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.4113 - acc: 0.8111 - val_loss: 1.1408e-22 - val_acc: 1.0000\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 0.2895 - acc: 0.8778 - val_loss: 6.4961 - val_acc: 0.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.3055 - acc: 0.8639 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2670 - acc: 0.8917 - val_loss: 5.1415 - val_acc: 0.9750\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2550 - acc: 0.8944 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2423 - acc: 0.9056 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2404 - acc: 0.9056 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        20\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        40\n",
      "   macro avg       1.00      1.00      1.00        40\n",
      "weighted avg       1.00      1.00      1.00        40\n",
      "\n",
      "Kfold iteration 6/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.8944 - acc: 0.5083 - val_loss: 159.2387 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.7450 - acc: 0.5389 - val_loss: 34.2233 - val_acc: 0.7750\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4878 - acc: 0.7750 - val_loss: 23.5229 - val_acc: 0.9500\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.3885 - acc: 0.8333 - val_loss: 18.3379 - val_acc: 0.9250\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.3335 - acc: 0.8528 - val_loss: 35.5627 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2539 - acc: 0.9056 - val_loss: 43.4103 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.3085 - acc: 0.8750 - val_loss: 21.6513 - val_acc: 0.9500\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2886 - acc: 0.8833 - val_loss: 31.3040 - val_acc: 0.9500\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2844 - acc: 0.8889 - val_loss: 23.8666 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.2190 - acc: 0.9083 - val_loss: 28.5025 - val_acc: 0.9500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        20\n",
      "           1       0.95      0.95      0.95        20\n",
      "\n",
      "    accuracy                           0.95        40\n",
      "   macro avg       0.95      0.95      0.95        40\n",
      "weighted avg       0.95      0.95      0.95        40\n",
      "\n",
      "Kfold iteration 7/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.9127 - acc: 0.5417 - val_loss: 110.4217 - val_acc: 0.5000\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 0.6022 - acc: 0.6944 - val_loss: 7.6351 - val_acc: 0.9250\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.4386 - acc: 0.7917 - val_loss: 4.3691 - val_acc: 0.9500\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.4245 - acc: 0.8028 - val_loss: 30.1685 - val_acc: 0.8750\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.3229 - acc: 0.8722 - val_loss: 4.2872 - val_acc: 0.9500\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2808 - acc: 0.8722 - val_loss: 32.1636 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3289 - acc: 0.8639 - val_loss: 4.7617 - val_acc: 0.9750\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2430 - acc: 0.9139 - val_loss: 3.8748 - val_acc: 0.9500\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1735 - acc: 0.9222 - val_loss: 18.9647 - val_acc: 0.9750\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2083 - acc: 0.9222 - val_loss: 10.2962 - val_acc: 0.9750\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        20\n",
      "           1       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.98      0.97      0.97        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "Kfold iteration 8/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.8205 - acc: 0.5611 - val_loss: 29.5215 - val_acc: 0.7000\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5879 - acc: 0.6972 - val_loss: 3.0924 - val_acc: 0.9500\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.3851 - acc: 0.8389 - val_loss: 6.6134 - val_acc: 0.9250\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.3212 - acc: 0.8722 - val_loss: 47.4679 - val_acc: 0.9000\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2783 - acc: 0.8806 - val_loss: 9.7071 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2587 - acc: 0.9056 - val_loss: 11.0783 - val_acc: 0.9500\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2648 - acc: 0.9028 - val_loss: 24.8136 - val_acc: 0.9250\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2051 - acc: 0.9306 - val_loss: 21.1295 - val_acc: 0.9500\n",
      "\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.2131 - acc: 0.9167 - val_loss: 22.1419 - val_acc: 0.9500\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 0.1902 - acc: 0.9361 - val_loss: 0.7821 - val_acc: 0.9750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97        20\n",
      "           1       0.95      1.00      0.98        20\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.98      0.97      0.97        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "Kfold iteration 9/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.9840 - acc: 0.4722 - val_loss: 2.5734 - val_acc: 0.9250\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 0.5751 - acc: 0.6889 - val_loss: 10.1290 - val_acc: 0.9000\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 0.4316 - acc: 0.8000 - val_loss: 4.3894 - val_acc: 0.9500\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3106 - acc: 0.8750 - val_loss: 29.0362 - val_acc: 0.9000\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2867 - acc: 0.8806 - val_loss: 37.0283 - val_acc: 0.9000\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.2917 - acc: 0.8833 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2231 - acc: 0.9333 - val_loss: 0.0000e+00 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.2987 - acc: 0.8889 - val_loss: 18.7685 - val_acc: 0.9250\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2877 - acc: 0.8750 - val_loss: 51.9503 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3223 - acc: 0.8667 - val_loss: 1.5366 - val_acc: 0.9750\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        20\n",
      "           1       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.97        40\n",
      "   macro avg       0.98      0.97      0.97        40\n",
      "weighted avg       0.98      0.97      0.97        40\n",
      "\n",
      "Kfold iteration 10/10\n",
      "Total images: 400 ---- Train images: 360 ---- Test images: 40\n",
      "Epoch 1/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.6940 - acc: 0.6056 - val_loss: 32.0663 - val_acc: 0.8750\n",
      "Epoch 2/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.5510 - acc: 0.7472 - val_loss: 27.9313 - val_acc: 0.8750\n",
      "Epoch 3/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.4333 - acc: 0.7806 - val_loss: 46.6798 - val_acc: 0.9000\n",
      "Epoch 4/10\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 0.3584 - acc: 0.8444 - val_loss: 63.0910 - val_acc: 0.8750\n",
      "Epoch 5/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.3283 - acc: 0.8889 - val_loss: 51.9538 - val_acc: 0.8750\n",
      "Epoch 6/10\n",
      "18/18 [==============================] - 1s 28ms/step - loss: 0.3001 - acc: 0.8889 - val_loss: 53.0214 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 7/10\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 0.2432 - acc: 0.9000 - val_loss: 49.0299 - val_acc: 0.9000\n",
      "Epoch 8/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2064 - acc: 0.9111 - val_loss: 61.8682 - val_acc: 0.9000\n",
      "Epoch 9/10\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 0.2092 - acc: 0.9222 - val_loss: 74.2074 - val_acc: 0.9000\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/10\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 0.1840 - acc: 0.9306 - val_loss: 61.4883 - val_acc: 0.9250\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92        20\n",
      "           1       0.87      1.00      0.93        20\n",
      "\n",
      "    accuracy                           0.93        40\n",
      "   macro avg       0.93      0.93      0.92        40\n",
      "weighted avg       0.93      0.93      0.92        40\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# All classification reports will be added here. When we are done we can average the f1 scores\n",
    "reports = []\n",
    "\n",
    "# Apply stratified K-fold ith 10 splits. Stratified means the same distribution of classes than the whole dataset\n",
    "# In this case, 50-50\n",
    "kf = StratifiedKFold(n_splits=10)\n",
    "\n",
    "# Just for printing purposes\n",
    "id = 1\n",
    "\n",
    "for train_index, test_index in kf.split(x,y):\n",
    "    print('Kfold iteration {}/10'.format(id))\n",
    "    print('Total images: {} ---- Train images: {} ---- Test images: {}'.format(len(x),len(train_index),len(test_index)))\n",
    "\n",
    "    id += 1 \n",
    "    \n",
    "    X_train, X_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "    model = pizza_model()\n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                 rotation_range=10, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                                 width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "                                 height_shift_range=0.1, \n",
    "                                 shear_range=0.1,\n",
    "                                 zoom_range=0.1)   \n",
    "    \n",
    "    datagen.fit(X_train)\n",
    "\n",
    "    # Secret sauce to get 3-5 % accuracy more\n",
    "    # Adjust the learning rate over time. (Like we saw in class!)\n",
    "    # The learning rate determines the size of the steps taken during the gradient descent process.\n",
    "    \n",
    "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n",
    "                                            patience=3, \n",
    "                                            verbose=1, \n",
    "                                            factor=0.5, \n",
    "                                            min_lr=0.00001)\n",
    "    \n",
    "    # Used to prevent overfitting. \n",
    "    # es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=50)\n",
    "    \n",
    "    history = model.fit_generator(datagen.flow(X_train, y_train, batch_size = 20), epochs = 10, \n",
    "                              validation_data = (X_test,y_test), steps_per_epoch=len(X_train) / 20,\n",
    "                              callbacks=[learning_rate_reduction])\n",
    "\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = [np.round(p[0]) for p in y_pred]\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))\n",
    "    reports.append(classification_report(y_test, y_pred,output_dict=True))\n",
    "    \n",
    "#     if id == 3:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1-Score is: 96.24%\n"
     ]
    }
   ],
   "source": [
    "# We loop over all reports (1 per fold) and then compute the average of all weighted f1 scores\n",
    "final_f1_score = np.mean([rep['weighted avg']['f1-score'] for rep in reports])\n",
    "\n",
    "print('Final F1-Score is: {}%'.format(np.round(final_f1_score*100,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
